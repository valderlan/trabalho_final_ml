# Trabalho Final - Machine Learning

## ğŸ“‹ SumÃ¡rio

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Requisitos](#-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Pipeline Completo](#-pipeline-completo)
  - [Etapa 1: Balanceamento do Dataset](#etapa-1-balanceamento-do-dataset)
  - [Etapa 2: AnÃ¡lise ExploratÃ³ria (EDA)](#etapa-2-anÃ¡lise-exploratÃ³ria-eda)
  - [Etapa 3: PrÃ©-processamento](#etapa-3-prÃ©-processamento)
  - [Etapa 4: Treinamento dos Modelos](#etapa-4-treinamento-dos-modelos)
  - [Etapa 5: Servindo a API](#etapa-5-servindo-a-api)
- [Uso da API](#-uso-da-api)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Artefatos Gerados](#-artefatos-gerados)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um **pipeline completo de Machine Learning** para classificaÃ§Ã£o, desde o balanceamento de dados atÃ© a disponibilizaÃ§Ã£o de uma API REST para inferÃªncia. O sistema:

1. **Balanceia** datasets desbalanceados usando undersampling
2. **Analisa** os dados atravÃ©s de anÃ¡lise exploratÃ³ria (EDA)
3. **PrÃ©-processa** e normaliza as features
4. **Treina e compara** mÃºltiplos modelos (Sklearn e PyTorch)
5. **Exporta** o melhor modelo para ONNX
6. **Serve** prediÃ§Ãµes atravÃ©s de uma API FastAPI

---

## ğŸ“¦ Requisitos

- **Python**: 3.13+
- **DependÃªncias**: Definidas em `pyproject.toml`

### Principais bibliotecas:
- `scikit-learn`: Modelos clÃ¡ssicos de ML
- `torch`: Redes neurais (CNN)
- `pandas`, `numpy`: ManipulaÃ§Ã£o de dados
- `matplotlib`, `seaborn`: VisualizaÃ§Ãµes
- `fastapi`, `uvicorn`: API REST
- `onnx`, `onnxruntime`: ExportaÃ§Ã£o e inferÃªncia de modelos
- `skl2onnx`: ConversÃ£o de modelos Sklearn para ONNX

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/valderlan/trabalho_final_ml.git
cd trabalho_final_ml
```

### 2. Instale as dependÃªncias

**Usando uv (recomendado):**
```bash
uv sync
```

**Ou usando pip:**
```bash
pip install -e .
```

---

## ğŸ”„ Pipeline Completo

### Etapa 1: Balanceamento do Dataset

**Arquivo:** `balancear_dataset.py`

**Objetivo:** Equilibrar as classes do dataset atravÃ©s de undersampling, garantindo que todas as classes tenham o mesmo nÃºmero de amostras da classe minoritÃ¡ria.

#### Como funciona:

1. **Leitura em chunks**: Processa grandes arquivos CSV em blocos de 200.000 linhas
2. **Contagem de classes**: Identifica a distribuiÃ§Ã£o original de cada classe
3. **Undersampling**: Reduz as classes majoritÃ¡rias ao tamanho da classe minoritÃ¡ria
4. **Escrita streaming**: Salva o dataset balanceado sem sobrecarregar a memÃ³ria

#### ExecuÃ§Ã£o:

```bash
python balancear_dataset.py
```

**ParÃ¢metros configurÃ¡veis no cÃ³digo:**
```python
input_csv = "dataset/dataset_original.csv"  # Dataset de entrada
target_column = "label"                      # Nome da coluna de classe
output_csv = "dataset/dataset_balanceado.csv" # Dataset de saÃ­da
```

**SaÃ­da:**
- `dataset/dataset_balanceado.csv`: Dataset com classes equilibradas

---

### Etapa 2: AnÃ¡lise ExploratÃ³ria (EDA)

**Arquivo:** `EDA.py`

**Objetivo:** Realizar anÃ¡lise exploratÃ³ria dos dados, identificar padrÃµes, remover outliers e gerar visualizaÃ§Ãµes.

#### Funcionalidades:

1. **RemoÃ§Ã£o de valores ausentes**:
   - Colunas: Remove colunas com qualquer valor NaN
   - Linhas: Opcionalmente remove linhas com NaN

2. **RemoÃ§Ã£o de outliers**:
   - MÃ©todo IQR (Interquartile Range)
   - Identifica valores fora de Q1 - 1.5Ã—IQR e Q3 + 1.5Ã—IQR

3. **GeraÃ§Ã£o de visualizaÃ§Ãµes**:
   - DistribuiÃ§Ã£o de classes
   - Matriz de correlaÃ§Ã£o entre features
   - Boxplots e histogramas

4. **RelatÃ³rio JSON**:
   - EstatÃ­sticas descritivas
   - InformaÃ§Ãµes sobre limpeza
   - AnÃ¡lise de classes

#### ExecuÃ§Ã£o:

```bash
python EDA.py
```

**ParÃ¢metros principais (modificar no cÃ³digo):**
```python
csv_path = "dataset/dataset_balanceado.csv"
label_column = "label"
remove_outliers = True   # Ativar/desativar remoÃ§Ã£o de outliers
drop_rows_with_nan = False
drop_cols_with_nan = True
```

**SaÃ­das:**
- `dataset/dataset_processed_final.csv`: Dataset limpo
- `figures/class_distribution.png`: GrÃ¡fico de distribuiÃ§Ã£o
- `figures/correlation_matrix.png`: Matriz de correlaÃ§Ã£o
- `json/eda_report.json`: RelatÃ³rio completo da anÃ¡lise
- `logs/eda_report.log`: Log detalhado do processo

---

### Etapa 3: PrÃ©-processamento

**Arquivo:** `preprocessing.py`

**Objetivo:** Preparar os dados para treinamento atravÃ©s de normalizaÃ§Ã£o e divisÃ£o em conjuntos de treino/teste.

#### Processo:

1. **Carregamento**: LÃª o dataset processado
2. **SeparaÃ§Ã£o**: Divide features (X) e target (y)
3. **CodificaÃ§Ã£o**: Converte labels categÃ³ricas em numÃ©ricas usando `LabelEncoder`
4. **DivisÃ£o**: Split 80/20 para treino/teste com estratificaÃ§Ã£o
5. **NormalizaÃ§Ã£o**: Aplica `StandardScaler` (mÃ©dia=0, desvio=1)
6. **Salvamento**: Persiste os arrays NumPy e transformadores

#### ExecuÃ§Ã£o:

```bash
python preprocessing.py
```

**ParÃ¢metros (modificar no cÃ³digo):**
```python
input_csv = "dataset/dataset_processed_final.csv"
target_col = "label"
test_size = 0.2  # 20% para teste
```

**SaÃ­das:**
- `dataset/processed/X_train.npy`: Features de treino normalizadas
- `dataset/processed/X_test.npy`: Features de teste normalizadas
- `dataset/processed/y_train.npy`: Labels de treino codificadas
- `dataset/processed/y_test.npy`: Labels de teste codificadas
- `models/scaler.pkl`: StandardScaler treinado
- `models/label_encoder.pkl`: LabelEncoder para decodificaÃ§Ã£o
- `json/metadata.json`: Metadados (n_features, n_classes, mapeamento)
- `logs/preprocessing.log`: Log do processo

---

### Etapa 4: Treinamento dos Modelos

**Arquivo:** `train.py`

**Objetivo:** Treinar mÃºltiplos modelos de classificaÃ§Ã£o, comparar desempenho e exportar o melhor para ONNX.

#### Modelos Treinados:

**Sklearn:**
1. **Logistic Regression**: ClassificaÃ§Ã£o linear
2. **K-Nearest Neighbors (KNN)**: Baseado em proximidade
3. **Decision Tree**: Ãrvore de decisÃ£o
4. **Random Forest**: Ensemble de Ã¡rvores
5. **Extra Trees**: Ensemble com divisÃµes aleatÃ³rias
6. **MLP (Multi-Layer Perceptron)**: Rede neural Sklearn

**PyTorch:**
7. **CNN (Convolutional Neural Network)**: Rede convolucional 1D

#### Grid Search:

Cada modelo passa por **Grid Search com validaÃ§Ã£o cruzada** (5-fold) para encontrar os melhores hiperparÃ¢metros.

Exemplos de grids:
```python
"LogisticRegression": {"C": [0.1, 1, 10]}
"KNN": {"n_neighbors": [3, 5, 7], "weights": ["uniform", "distance"]}
"RandomForest": {"n_estimators": [100, 200], "max_depth": [10, 20, None]}
```

#### MÃ©tricas Calculadas:

- **Accuracy**: AcurÃ¡cia geral
- **F1-Score (Macro)**: MÃ©dia harmÃ´nica de precisÃ£o e recall
- **Recall (Macro)**: Taxa de verdadeiros positivos
- **Precision (Macro)**: Taxa de prediÃ§Ãµes corretas
- **MCC (Matthews Correlation Coefficient)**: CorrelaÃ§Ã£o entre predito e real
- **Log Loss**: Perda logarÃ­tmica (quando aplicÃ¡vel)

#### VisualizaÃ§Ãµes:

Para cada modelo:
- **Matriz de ConfusÃ£o**: `figures/cm_{modelo}.png`
- **Feature Importance** (quando disponÃ­vel): `figures/feature_importance_{modelo}.png`

#### ExportaÃ§Ã£o ONNX:

Todos os modelos sÃ£o exportados para o formato **ONNX** (Open Neural Network Exchange):
- Permite inferÃªncia rÃ¡pida e independente de framework
- CompatÃ­vel com mÃºltiplas linguagens e plataformas

#### ExecuÃ§Ã£o:

```bash
python train.py
```

**Processo automÃ¡tico:**
1. Carrega dados do prÃ©-processamento
2. Para cada modelo:
   - Executa Grid Search
   - Treina com melhores parÃ¢metros
   - Avalia em treino e teste
   - Gera visualizaÃ§Ãµes
   - Exporta para ONNX
3. Compara todos os modelos
4. Copia o melhor para `models/best_model.onnx`

**SaÃ­das:**
- `models/{modelo}.onnx`: Cada modelo em ONNX
- `models/best_model.onnx`: Melhor modelo (cÃ³pia)
- `dataset/processed/model_comparison_results.csv`: ComparaÃ§Ã£o de mÃ©tricas
- `figures/cm_*.png`: Matrizes de confusÃ£o
- `figures/feature_importance_*.png`: ImportÃ¢ncia de features
- `json/training_metrics.json`: MÃ©tricas detalhadas de todos os modelos
- `logs/training.log`: Log completo do treinamento

#### CritÃ©rio de SeleÃ§Ã£o do Melhor Modelo:

O modelo com **maior F1-Score Macro no conjunto de teste** Ã© escolhido como o melhor.

---

### Etapa 5: Servindo a API

**Arquivo:** `app.py`

**Objetivo:** Disponibilizar uma API REST para realizar prediÃ§Ãµes usando o melhor modelo treinado.

#### Arquitetura:

- **Framework**: FastAPI (moderna, rÃ¡pida, assÃ­ncrona)
- **InferÃªncia**: ONNX Runtime (otimizado para produÃ§Ã£o)
- **Servidor**: Uvicorn (ASGI server)

#### InicializaÃ§Ã£o:

No startup, a API carrega:
1. `json/metadata.json`: ConfiguraÃ§Ãµes do modelo
2. `models/scaler.pkl`: Para normalizaÃ§Ã£o dos inputs
3. `models/best_model.onnx`: Modelo para inferÃªncia

#### Endpoint DisponÃ­vel:

**POST** `/predict`

Recebe um JSON com as features e retorna a prediÃ§Ã£o.

#### ExecuÃ§Ã£o:

```bash
python app.py
```

Ou diretamente com uvicorn:
```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

**Servidor rodando em:** `http://localhost:8000`

**DocumentaÃ§Ã£o interativa:**
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

---

## ğŸ”Œ Uso da API

### 1. Verificar se a API estÃ¡ rodando

Acesse no navegador: `http://localhost:8000/docs`

### 2. Fazer uma prediÃ§Ã£o

#### Via cURL:

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "features": [0.5, 1.2, -0.3, 0.8, 1.5, 0.2, -0.7, 0.9, 0.4, -0.1]
  }'
```

#### Via Python:

```python
import requests

url = "http://localhost:8000/predict"
data = {
    "features": [0.5, 1.2, -0.3, 0.8, 1.5, 0.2, -0.7, 0.9, 0.4, -0.1]
}

response = requests.post(url, json=data)
print(response.json())
```

#### Resposta esperada:

```json
{
  "prediction_id": 1,
  "class_name": "ClasseA",
  "model_type": "ONNX Inference"
}
```

### 3. ValidaÃ§Ãµes:

A API valida automaticamente:
- âœ… NÃºmero correto de features
- âœ… Tipos de dados vÃ¡lidos
- âœ… Modelo carregado corretamente

#### Erro se nÃºmero de features incorreto:

```json
{
  "detail": "Esperado 10 features."
}
```

---

## ğŸ“ Estrutura do Projeto

```
trabalho_final_ml/
â”œâ”€â”€ app.py                          # API FastAPI
â”œâ”€â”€ balancear_dataset.py            # Balanceamento de classes
â”œâ”€â”€ EDA.py                          # AnÃ¡lise exploratÃ³ria
â”œâ”€â”€ preprocessing.py                # PrÃ©-processamento
â”œâ”€â”€ train.py                        # Treinamento de modelos
â”œâ”€â”€ pyproject.toml                  # DependÃªncias e metadados
â”œâ”€â”€ README.md                       # Esta documentaÃ§Ã£o
â”œâ”€â”€ relatorio_comparativo.md        # ComparaÃ§Ã£o de modelos
â”‚
â”œâ”€â”€ dataset/                        # Dados
â”‚   â”œâ”€â”€ dataset_balanceado.csv      # Dataset balanceado
â”‚   â”œâ”€â”€ dataset_processed_final.csv # Dataset limpo (EDA)
â”‚   â””â”€â”€ processed/                  # Arrays NumPy
â”‚       â”œâ”€â”€ X_train.npy
â”‚       â”œâ”€â”€ X_test.npy
â”‚       â”œâ”€â”€ y_train.npy
â”‚       â”œâ”€â”€ y_test.npy
â”‚       â””â”€â”€ model_comparison_results.csv
â”‚
â”œâ”€â”€ models/                         # Modelos treinados
â”‚   â”œâ”€â”€ best_model.onnx             # Melhor modelo
â”‚   â”œâ”€â”€ scaler.pkl                  # StandardScaler
â”‚   â”œâ”€â”€ label_encoder.pkl           # LabelEncoder
â”‚   â”œâ”€â”€ LogisticRegression.onnx
â”‚   â”œâ”€â”€ KNN.onnx
â”‚   â”œâ”€â”€ DecisionTree.onnx
â”‚   â”œâ”€â”€ RandomForest.onnx
â”‚   â”œâ”€â”€ ExtraTrees.onnx
â”‚   â”œâ”€â”€ MLP_Sklearn.onnx
â”‚   â””â”€â”€ CNN_PyTorch.onnx
â”‚
â”œâ”€â”€ figures/                        # VisualizaÃ§Ãµes
â”‚   â”œâ”€â”€ class_distribution.png
â”‚   â”œâ”€â”€ correlation_matrix.png
â”‚   â”œâ”€â”€ cm_*.png                    # Matrizes de confusÃ£o
â”‚   â””â”€â”€ feature_importance_*.png
â”‚
â”œâ”€â”€ json/                           # Metadados e relatÃ³rios
â”‚   â”œâ”€â”€ metadata.json               # ConfiguraÃ§Ãµes do modelo
â”‚   â”œâ”€â”€ eda_report.json             # RelatÃ³rio da EDA
â”‚   â””â”€â”€ training_metrics.json      # MÃ©tricas de treinamento
â”‚
â””â”€â”€ logs/                           # Logs de execuÃ§Ã£o
    â”œâ”€â”€ eda_report.log
    â”œâ”€â”€ preprocessing.log
    â””â”€â”€ training.log
```

---

## ğŸ“Š Artefatos Gerados

### Datasets:
- `dataset_balanceado.csv`: Classes equilibradas
- `dataset_processed_final.csv`: Dados limpos e prontos
- `X_train.npy`, `X_test.npy`, `y_train.npy`, `y_test.npy`: Arrays normalizados

### Modelos:
- `*.onnx`: Modelos exportados
- `best_model.onnx`: Modelo de produÃ§Ã£o
- `scaler.pkl`, `label_encoder.pkl`: Transformadores

### RelatÃ³rios:
- `eda_report.json`: EstatÃ­sticas e anÃ¡lise
- `metadata.json`: ConfiguraÃ§Ãµes e mapeamentos
- `training_metrics.json`: MÃ©tricas de todos os modelos
- `model_comparison_results.csv`: ComparaÃ§Ã£o tabular

### VisualizaÃ§Ãµes:
- `class_distribution.png`: DistribuiÃ§Ã£o de classes
- `correlation_matrix.png`: CorrelaÃ§Ãµes entre features
- `cm_*.png`: Matrizes de confusÃ£o de cada modelo
- `feature_importance_*.png`: ImportÃ¢ncia de features

### Logs:
- `eda_report.log`: Log da anÃ¡lise exploratÃ³ria
- `preprocessing.log`: Log do prÃ©-processamento
- `training.log`: Log detalhado do treinamento

---

## ğŸ“ Fluxo Completo de ExecuÃ§Ã£o

Para executar o pipeline completo do zero:

```bash
# 1. Balancear o dataset
python balancear_dataset.py

# 2. Realizar anÃ¡lise exploratÃ³ria
python EDA.py

# 3. PrÃ©-processar os dados
python preprocessing.py

# 4. Treinar todos os modelos
python train.py

# 5. Iniciar a API
python app.py
```

ApÃ³s esses passos, vocÃª terÃ¡:
- âœ… Dataset balanceado e limpo
- âœ… VisualizaÃ§Ãµes e relatÃ³rios
- âœ… 7 modelos treinados e comparados
- âœ… API REST servindo o melhor modelo

---

## ğŸ”§ CustomizaÃ§Ãµes

### Adicionar novos modelos:

Edite `train.py` e adicione no dicionÃ¡rio `models_config`:

```python
"SeuModelo": {
    "model": SeuClassificador(),
    "params": {"param1": [val1, val2], "param2": [val3, val4]}
}
```

### Modificar hiperparÃ¢metros:

Ajuste os grids de busca em `train.py`:

```python
"RandomForest": {
    "model": RandomForestClassifier(random_state=42),
    "params": {
        "n_estimators": [50, 100, 200, 500],
        "max_depth": [5, 10, 20, None],
        "min_samples_split": [2, 5, 10]
    }
}
```

### Alterar split de treino/teste:

Em `preprocessing.py`, modifique:

```python
test_size = 0.3  # 30% para teste
```

---

## ğŸ“ Notas Importantes

1. **MemÃ³ria**: O balanceamento em streaming permite processar datasets grandes sem problemas
2. **ONNX**: Formato universal para modelos, possibilita deploy em diversas plataformas
3. **Grid Search**: Pode ser demorado para modelos complexos; ajuste os grids conforme necessÃ¡rio
4. **Logs**: Sempre verifique os logs em caso de erros
5. **API**: Em produÃ§Ã£o, considere adicionar autenticaÃ§Ã£o e rate limiting

---

## ğŸ¤ ContribuiÃ§Ãµes

Este projeto Ã© parte do trabalho final da disciplina de Machine Learning e MineraÃ§Ã£o de Dados.

**Autor:** Valderlan  
**RepositÃ³rio:** [github.com/valderlan/trabalho_final_ml](https://github.com/valderlan/trabalho_final_ml)

---

## ğŸ“„ LicenÃ§a

[Especifique a licenÃ§a aqui]